{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here are some imports that are used along this notebook\n",
    "import math\n",
    "import itertools\n",
    "import pandas\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "import seaborn as sns\n",
    "from time import time\n",
    "import tensorflow as tf\n",
    "from collections import OrderedDict\n",
    "import keras\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.utils import np_utils\n",
    "%matplotlib inline\n",
    "gt0 = time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_nsl_kdd_dataset_path = \"NSL_KDD_Dataset/KDDTrain+.txt\"\n",
    "test_nsl_kdd_dataset_path = \"NSL_KDD_Dataset/KDDTest+.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "col_names = np.array([\"duration\",\"protocol_type\",\"service\",\"flag\",\"src_bytes\",\n",
    "    \"dst_bytes\",\"land\",\"wrong_fragment\",\"urgent\",\"hot\",\"num_failed_logins\",\n",
    "    \"logged_in\",\"num_compromised\",\"root_shell\",\"su_attempted\",\"num_root\",\n",
    "    \"num_file_creations\",\"num_shells\",\"num_access_files\",\"num_outbound_cmds\",\n",
    "    \"is_host_login\",\"is_guest_login\",\"count\",\"srv_count\",\"serror_rate\",\n",
    "    \"srv_serror_rate\",\"rerror_rate\",\"srv_rerror_rate\",\"same_srv_rate\",\n",
    "    \"diff_srv_rate\",\"srv_diff_host_rate\",\"dst_host_count\",\"dst_host_srv_count\",\n",
    "    \"dst_host_same_srv_rate\",\"dst_host_diff_srv_rate\",\"dst_host_same_src_port_rate\",\n",
    "    \"dst_host_srv_diff_host_rate\",\"dst_host_serror_rate\",\"dst_host_srv_serror_rate\",\n",
    "    \"dst_host_rerror_rate\",\"dst_host_srv_rerror_rate\",\"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "attack_dict_five_class = {\n",
    "    'normal': 'normal',\n",
    "    \n",
    "    'back': 'DoS',\n",
    "    'land': 'DoS',\n",
    "    'neptune': 'DoS',\n",
    "    'pod': 'DoS',\n",
    "    'smurf': 'DoS',\n",
    "    'teardrop': 'DoS',\n",
    "    'mailbomb': 'DoS',\n",
    "    'apache2': 'DoS',\n",
    "    'processtable': 'DoS',\n",
    "    'udpstorm': 'DoS',\n",
    "    \n",
    "    'ipsweep': 'Probe',\n",
    "    'nmap': 'Probe',\n",
    "    'portsweep': 'Probe',\n",
    "    'satan': 'Probe',\n",
    "    'mscan': 'Probe',\n",
    "    'saint': 'Probe',\n",
    "\n",
    "    'ftp_write': 'R2L',\n",
    "    'guess_passwd': 'R2L',\n",
    "    'imap': 'R2L',\n",
    "    'multihop': 'R2L',\n",
    "    'phf': 'R2L',\n",
    "    'spy': 'R2L',\n",
    "    'warezclient': 'R2L',\n",
    "    'warezmaster': 'R2L',\n",
    "    'sendmail': 'R2L',\n",
    "    'named': 'R2L',\n",
    "    'snmpgetattack': 'R2L',\n",
    "    'snmpguess': 'R2L',\n",
    "    'xlock': 'R2L',\n",
    "    'xsnoop': 'R2L',\n",
    "    'worm': 'R2L',\n",
    "    \n",
    "    'buffer_overflow': 'U2R',\n",
    "    'loadmodule': 'U2R',\n",
    "    'perl': 'U2R',\n",
    "    'rootkit': 'U2R',\n",
    "    'httptunnel': 'U2R',\n",
    "    'ps': 'U2R',    \n",
    "    'sqlattack': 'U2R',\n",
    "    'xterm': 'U2R'\n",
    "}\n",
    "\n",
    "attack_two_class = []\n",
    "for key in attack_dict_five_class.keys():\n",
    "    if key == 'normal':\n",
    "        pass\n",
    "    else:\n",
    "        attack_two_class.append(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Load test and train data\n",
    "train_df = pd.read_csv(train_nsl_kdd_dataset_path, names = col_names)\n",
    "test_df  = pd.read_csv(test_nsl_kdd_dataset_path , names = col_names)\n",
    "train_labels = train_df.pop('dst_host_srv_rerror_rate')\n",
    "test_labels = test_df.pop('dst_host_srv_rerror_rate')\n",
    "total_dataset = pd.concat([train_df, test_df])\n",
    "#print(total_dataset.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(148517, 41)"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "total_dataset.head()\n",
    "total_dataset.shape\n",
    "#train_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print(pd.get_dummies(train_df, columns=['flag']))\n",
    "#get = train_df.pop('protocol_type')\n",
    "#print(get)\n",
    "#pd.get_dummies(get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#test_df.head(),train_df.head()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(125973, 122) (22544, 122)\n"
     ]
    }
   ],
   "source": [
    "total_dataset = pd.get_dummies(total_dataset)\n",
    "#print(total_dataset.shape)\n",
    "#train_size = int(len(total_dataset) * 0.80)\n",
    "#print(train_size)\n",
    "#test_size = len(total_dataset) - train_size\n",
    "#print(test_size)\n",
    "train_df = total_dataset.iloc[0:125973, :]\n",
    "test_df = total_dataset.iloc[125973:, :]\n",
    "print(train_df.shape, test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_labels_for_two_class = pd.DataFrame(test_labels.as_matrix(), columns=[\"class\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_labels_for_two_class = pd.DataFrame(train_labels.as_matrix(), columns=[\"class\"])\n",
    "#print(train_labels_for_two_class)\n",
    "test_labels_for_two_class = pd.DataFrame(test_labels.as_matrix(), columns=[\"class\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_labels_for_two_class.loc[train_labels_for_two_class['class'].isin(attack_two_class) , 'class'] = 1\n",
    "train_labels_for_two_class.loc[train_labels_for_two_class['class'] == \"normal\" , 'class'] = 0\n",
    "#print(train_labels_for_two_class)\n",
    "#for test labels \n",
    "test_labels_for_two_class.loc[test_labels_for_two_class['class'].isin(attack_two_class) , 'class'] = 1\n",
    "test_labels_for_two_class.loc[test_labels_for_two_class['class'] == \"normal\" , 'class'] = 0\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(125973, 2)\n",
      "(125973, 2)\n"
     ]
    }
   ],
   "source": [
    "train_labels_for_two_class = np_utils.to_categorical(train_labels_for_two_class)\n",
    "print(train_labels_for_two_class.shape)\n",
    "test_labels_for_two_class = np_utils.to_categorical(test_labels_for_two_class)\n",
    "print(train_labels_for_two_class.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22544, 122)"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#min-max mazimazation for the data\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "train_X = train_df.as_matrix()\n",
    "train_Y = train_labels_for_two_class\n",
    "\n",
    "test_X = test_df.as_matrix()\n",
    "test_Y = test_labels_for_two_class\n",
    "scaler = MinMaxScaler() \n",
    "scaler.fit_transform(train_X)\n",
    "scaler.fit_transform(train_Y)\n",
    "scaler.fit_transform(test_X)\n",
    "scaler.fit_transform(test_Y)\n",
    "#train_X.shape[1]\n",
    "test_X.shape\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Training our auto encoder\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, Dense\n",
    "from keras import regularizers\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print(train_X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = train_X.shape[1]\n",
    "input_layer = Input(shape=(input_dim, ))\n",
    "encoded = Dense(30, activation=\"relu\", \n",
    "                activity_regularizer=regularizers.l1(10e-5))(input_layer)\n",
    "decoded = Dense(input_dim, activation='sigmoid')(encoded)\n",
    "autoencoder = Model(inputs=input_layer, outputs=decoded)\n",
    "encoder = Model(input_layer, encoded)\n",
    "encoded_input = Input(shape=(30,))\n",
    "decoder_layer = autoencoder.layers[-1]\n",
    "decoder = Model(encoded_input,decoder_layer(encoded_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 125973 samples, validate on 22544 samples\n",
      "Epoch 1/10\n",
      "125973/125973 [==============================] - 4s 34us/step - loss: 415028356685.5718 - acc: 0.1832 - val_loss: 1836718977.6833 - val_acc: 0.0790\n",
      "Epoch 2/10\n",
      "125973/125973 [==============================] - 4s 30us/step - loss: 415028358771.0134 - acc: 0.0780 - val_loss: 1836718922.0335 - val_acc: 0.1451\n",
      "Epoch 3/10\n",
      "125973/125973 [==============================] - 4s 30us/step - loss: 415028356487.2087 - acc: 0.1847 - val_loss: 1836718912.4815 - val_acc: 0.2134\n",
      "Epoch 4/10\n",
      "125973/125973 [==============================] - 4s 29us/step - loss: 415028358115.1174 - acc: 0.1872 - val_loss: 1836718927.5570 - val_acc: 0.1255\n",
      "Epoch 5/10\n",
      "125973/125973 [==============================] - 4s 30us/step - loss: 415028353651.5125 - acc: 0.1297 - val_loss: 1836718917.2064 - val_acc: 0.0914\n",
      "Epoch 6/10\n",
      "125973/125973 [==============================] - 4s 30us/step - loss: 415028358831.1180 - acc: 0.1082 - val_loss: 1836718903.7571 - val_acc: 0.1462\n",
      "Epoch 7/10\n",
      "125973/125973 [==============================] - 4s 30us/step - loss: 415028353789.3379 - acc: 0.1195 - val_loss: 1836718914.4776 - val_acc: 0.0700\n",
      "Epoch 8/10\n",
      "125973/125973 [==============================] - 4s 30us/step - loss: 415028352537.4432 - acc: 0.1254 - val_loss: 1836718908.9494 - val_acc: 0.1507\n",
      "Epoch 9/10\n",
      "125973/125973 [==============================] - 4s 30us/step - loss: 415028364055.1443 - acc: 0.1559 - val_loss: 1836718913.1203 - val_acc: 0.1382\n",
      "Epoch 10/10\n",
      "125973/125973 [==============================] - 4s 30us/step - loss: 415028355438.5737 - acc: 0.1834 - val_loss: 1836718917.5447 - val_acc: 0.1489\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d2266add68>"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_epoch = 10\n",
    "batch_size = 128\n",
    "autoencoder.compile(optimizer='adam', \n",
    "                    loss='mean_squared_error', \n",
    "                    metrics=['accuracy'])\n",
    "\n",
    "autoencoder.fit(train_X,train_X ,\n",
    "                    epochs=nb_epoch,\n",
    "                    verbose = 1,\n",
    "                    batch_size=batch_size,\n",
    "                    shuffle=True,\n",
    "                    validation_data=(test_X, test_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(125973, 30)"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = encoder.predict(train_X)\n",
    "#x_train\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(125973, 122)"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = decoder.predict(X)\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim_1 = X.shape[1]\n",
    "input_layer_1 = Input(shape=(input_dim_1, ))\n",
    "encoded_1 = Dense(20, activation=\"relu\", \n",
    "                activity_regularizer=regularizers.l1(10e-5))(input_layer_1)\n",
    "decoded_1 = Dense(input_dim_1, activation='sigmoid')(encoded_1)\n",
    "autoencoder_1 = Model(inputs=input_layer_1, outputs=decoded_1)\n",
    "encoder_1 = Model(input_layer_1, encoded_1)\n",
    "encoded_input_1 = Input(shape=(20,))\n",
    "decoder_layer_1 = autoencoder_1.layers[-1]\n",
    "decoder_1 = Model(encoded_input_1,decoder_layer_1(encoded_input_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "125973/125973 [==============================] - 2s 17us/step - loss: 244.5296 - acc: 0.9078\n",
      "Epoch 2/10\n",
      "125973/125973 [==============================] - 2s 13us/step - loss: 244.3257 - acc: 0.9451\n",
      "Epoch 3/10\n",
      "125973/125973 [==============================] - 2s 13us/step - loss: 244.3092 - acc: 0.9460\n",
      "Epoch 4/10\n",
      "125973/125973 [==============================] - 2s 13us/step - loss: 244.3003 - acc: 0.9460\n",
      "Epoch 5/10\n",
      "125973/125973 [==============================] - 2s 13us/step - loss: 244.2937 - acc: 0.9460\n",
      "Epoch 6/10\n",
      "125973/125973 [==============================] - 2s 13us/step - loss: 244.2885 - acc: 0.9460\n",
      "Epoch 7/10\n",
      "125973/125973 [==============================] - 2s 13us/step - loss: 244.2845 - acc: 0.9460\n",
      "Epoch 8/10\n",
      "125973/125973 [==============================] - 2s 13us/step - loss: 244.2814 - acc: 0.9460\n",
      "Epoch 9/10\n",
      "125973/125973 [==============================] - 2s 13us/step - loss: 244.2791 - acc: 0.9459\n",
      "Epoch 10/10\n",
      "125973/125973 [==============================] - 2s 13us/step - loss: 244.2774 - acc: 0.9458\n"
     ]
    }
   ],
   "source": [
    "nb_epoch = 10\n",
    "batch_size = 128\n",
    "autoencoder_1.compile(optimizer='adam', \n",
    "                    loss='mean_squared_error', \n",
    "                    metrics=['accuracy'])\n",
    "checkpointer = ModelCheckpoint(filepath=\"model.h5\",\n",
    "                               verbose=0,\n",
    "                               save_best_only=True)\n",
    "\n",
    "history = autoencoder_1.fit(X,X,\n",
    "                    epochs=nb_epoch,\n",
    "                    verbose = 1,\n",
    "                    batch_size=batch_size,\n",
    "                    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(125973, 20)"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z = encoder_1.predict(X)\n",
    "Z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_layer = Input(shape=(train_X.shape[1], ))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # encoded = Dense(30, activation=\"relu\", \n",
    "# #                 activity_regularizer=regularizers.l1(10e-5))(input_layer)\n",
    "\n",
    "# # encoder = Model(input_layer, encoded)\n",
    "# # encoded_1 = Dense(20, activation=\"relu\", \n",
    "# #                 activity_regularizer=regularizers.l1(10e-5))(encoder.output)\n",
    "# # encoder_1 = Model(, encoded_1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # encoded_2 = Dense(10, activation='relu')(input_layer_2)\n",
    "# # encoder_2 = Model(input_layer_2, encoded_2)\n",
    "# out2 = Dense(2, activation='softmax')(encoder_2.output)\n",
    "# newmodel = Model(encoder_2.input,out2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras import optimizers\n",
    "# opt = optimizers.SGD(lr=0.00001)\n",
    "# newmodel.compile(loss='categorical_crossentropy',\n",
    "#           optimizer=opt, \n",
    "#           metrics=['accuracy']) \n",
    "\n",
    "# newmodel.fit(train_X, train_Y,\n",
    "#       epochs=10,\n",
    "#       batch_size=128,\n",
    "#       shuffle=True,\n",
    "#       validation_data=(test_X, test_Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Layer\n",
    "from keras import optimizers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(encoder)\n",
    "model.add(encoder_1)\n",
    "model.add(Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 3s 52ms/step\n",
      "Accuracy:  0.543204426765\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(test_X, test_Y, verbose=1, steps=50) \n",
    "print(\"Accuracy: \", scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense\n",
    "from keras.activations import sigmoid\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\keras\\models.py:942: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 125973 samples, validate on 22544 samples\n",
      "Epoch 1/100\n",
      "125973/125973 [==============================] - 4s 29us/step - loss: 0.7451 - acc: 0.5510 - val_loss: 0.7109 - val_acc: 0.4308\n",
      "Epoch 2/100\n",
      "125973/125973 [==============================] - 3s 23us/step - loss: 0.6853 - acc: 0.5395 - val_loss: 0.9266 - val_acc: 0.6193\n",
      "Epoch 3/100\n",
      "125973/125973 [==============================] - 3s 23us/step - loss: 0.7717 - acc: 0.9008 - val_loss: 0.7286 - val_acc: 0.6845\n",
      "Epoch 4/100\n",
      "125973/125973 [==============================] - 3s 24us/step - loss: 0.3848 - acc: 0.9364 - val_loss: 1.7220 - val_acc: 0.7614\n",
      "Epoch 5/100\n",
      "125973/125973 [==============================] - 3s 23us/step - loss: 0.7246 - acc: 0.9436 - val_loss: 0.8081 - val_acc: 0.8012\n",
      "Epoch 6/100\n",
      "125973/125973 [==============================] - 3s 23us/step - loss: 0.2921 - acc: 0.9503 - val_loss: 1.7932 - val_acc: 0.7383\n",
      "Epoch 7/100\n",
      "125973/125973 [==============================] - 3s 23us/step - loss: 0.6049 - acc: 0.9449 - val_loss: 0.6975 - val_acc: 0.8168\n",
      "Epoch 8/100\n",
      "125973/125973 [==============================] - 3s 24us/step - loss: 0.3293 - acc: 0.9464 - val_loss: 0.7746 - val_acc: 0.7877\n",
      "Epoch 9/100\n",
      "125973/125973 [==============================] - 3s 23us/step - loss: 0.6614 - acc: 0.9505 - val_loss: 0.9196 - val_acc: 0.8008\n",
      "Epoch 10/100\n",
      "125973/125973 [==============================] - 3s 23us/step - loss: 0.3938 - acc: 0.9448 - val_loss: 1.0539 - val_acc: 0.7321\n",
      "Epoch 11/100\n",
      "125973/125973 [==============================] - 3s 24us/step - loss: 0.6553 - acc: 0.9555 - val_loss: 0.8504 - val_acc: 0.7394\n",
      "Epoch 12/100\n",
      "125973/125973 [==============================] - 3s 23us/step - loss: 0.5965 - acc: 0.9521 - val_loss: 0.6855 - val_acc: 0.8401\n",
      "Epoch 13/100\n",
      "125973/125973 [==============================] - 3s 23us/step - loss: 0.3904 - acc: 0.9446 - val_loss: 0.7327 - val_acc: 0.8428\n",
      "Epoch 14/100\n",
      "125973/125973 [==============================] - 3s 23us/step - loss: 0.5620 - acc: 0.9560 - val_loss: 0.8685 - val_acc: 0.8297\n",
      "Epoch 15/100\n",
      "125973/125973 [==============================] - 3s 23us/step - loss: 0.3868 - acc: 0.9585 - val_loss: 2.0546 - val_acc: 0.7521\n",
      "Epoch 16/100\n",
      "125973/125973 [==============================] - 3s 23us/step - loss: 0.5065 - acc: 0.9503 - val_loss: 1.2824 - val_acc: 0.7858\n",
      "Epoch 17/100\n",
      "125973/125973 [==============================] - 3s 23us/step - loss: 0.3986 - acc: 0.9576 - val_loss: 0.6592 - val_acc: 0.8505\n",
      "Epoch 18/100\n",
      "125973/125973 [==============================] - 3s 23us/step - loss: 0.3362 - acc: 0.9539 - val_loss: 1.2051 - val_acc: 0.7311\n",
      "Epoch 19/100\n",
      "125973/125973 [==============================] - 3s 23us/step - loss: 0.4410 - acc: 0.9552 - val_loss: 0.6917 - val_acc: 0.8438\n",
      "Epoch 20/100\n",
      "125973/125973 [==============================] - 3s 25us/step - loss: 0.2564 - acc: 0.9566 - val_loss: 0.7071 - val_acc: 0.7822\n",
      "Epoch 21/100\n",
      "125973/125973 [==============================] - 3s 23us/step - loss: 0.3251 - acc: 0.9618 - val_loss: 0.7209 - val_acc: 0.8418\n",
      "Epoch 22/100\n",
      "125973/125973 [==============================] - 3s 23us/step - loss: 0.5544 - acc: 0.9599 - val_loss: 0.8536 - val_acc: 0.8255\n",
      "Epoch 23/100\n",
      "125973/125973 [==============================] - 3s 23us/step - loss: 0.3418 - acc: 0.9551 - val_loss: 1.1794 - val_acc: 0.8144\n",
      "Epoch 24/100\n",
      "125973/125973 [==============================] - 3s 23us/step - loss: 0.4237 - acc: 0.9521 - val_loss: 0.5536 - val_acc: 0.8491\n",
      "Epoch 25/100\n",
      "125973/125973 [==============================] - 3s 24us/step - loss: 0.3582 - acc: 0.9410 - val_loss: 1.0697 - val_acc: 0.8159\n",
      "Epoch 26/100\n",
      "125973/125973 [==============================] - 3s 23us/step - loss: 0.3159 - acc: 0.9550 - val_loss: 1.0217 - val_acc: 0.8209\n",
      "Epoch 27/100\n",
      "125973/125973 [==============================] - 3s 23us/step - loss: 0.2660 - acc: 0.9568 - val_loss: 0.8044 - val_acc: 0.8333\n",
      "Epoch 28/100\n",
      "125973/125973 [==============================] - 3s 24us/step - loss: 0.4332 - acc: 0.9533 - val_loss: 0.7065 - val_acc: 0.8435\n",
      "Epoch 29/100\n",
      "125973/125973 [==============================] - 3s 25us/step - loss: 0.3179 - acc: 0.9546 - val_loss: 0.7663 - val_acc: 0.8446\n",
      "Epoch 30/100\n",
      "125973/125973 [==============================] - 3s 24us/step - loss: 0.3820 - acc: 0.9515 - val_loss: 0.7676 - val_acc: 0.8332\n",
      "Epoch 31/100\n",
      "125973/125973 [==============================] - 3s 24us/step - loss: 0.3263 - acc: 0.9606 - val_loss: 1.0801 - val_acc: 0.8257\n",
      "Epoch 32/100\n",
      "125973/125973 [==============================] - 3s 23us/step - loss: 0.2952 - acc: 0.9447 - val_loss: 0.9544 - val_acc: 0.8341\n",
      "Epoch 33/100\n",
      "125973/125973 [==============================] - 3s 24us/step - loss: 0.6799 - acc: 0.9510 - val_loss: 1.0572 - val_acc: 0.8267\n",
      "Epoch 34/100\n",
      "125973/125973 [==============================] - 3s 25us/step - loss: 0.2220 - acc: 0.9634 - val_loss: 0.6296 - val_acc: 0.8553\n",
      "Epoch 35/100\n",
      "125973/125973 [==============================] - 3s 26us/step - loss: 0.3673 - acc: 0.9515 - val_loss: 0.7930 - val_acc: 0.7897\n",
      "Epoch 36/100\n",
      "125973/125973 [==============================] - 3s 26us/step - loss: 0.7583 - acc: 0.9561 - val_loss: 0.9792 - val_acc: 0.8441\n",
      "Epoch 37/100\n",
      "125973/125973 [==============================] - 3s 25us/step - loss: 0.5524 - acc: 0.9567 - val_loss: 1.1229 - val_acc: 0.8275\n",
      "Epoch 38/100\n",
      "125973/125973 [==============================] - 3s 25us/step - loss: 0.5466 - acc: 0.9530 - val_loss: 0.8576 - val_acc: 0.8367\n",
      "Epoch 39/100\n",
      "125973/125973 [==============================] - 3s 25us/step - loss: 0.5842 - acc: 0.9597 - val_loss: 0.8583 - val_acc: 0.8410\n",
      "Epoch 40/100\n",
      "125973/125973 [==============================] - 3s 24us/step - loss: 0.3889 - acc: 0.9621 - val_loss: 1.4657 - val_acc: 0.7574\n",
      "Epoch 41/100\n",
      "125973/125973 [==============================] - 3s 24us/step - loss: 0.3526 - acc: 0.9485 - val_loss: 1.1783 - val_acc: 0.8436\n",
      "Epoch 42/100\n",
      "125973/125973 [==============================] - 3s 25us/step - loss: 0.3925 - acc: 0.9588 - val_loss: 1.1056 - val_acc: 0.7921\n",
      "Epoch 43/100\n",
      "125973/125973 [==============================] - 3s 26us/step - loss: 0.4998 - acc: 0.9596 - val_loss: 0.8536 - val_acc: 0.8270\n",
      "Epoch 44/100\n",
      "125973/125973 [==============================] - 3s 26us/step - loss: 0.4061 - acc: 0.9518 - val_loss: 0.8581 - val_acc: 0.8259\n",
      "Epoch 45/100\n",
      "125973/125973 [==============================] - 3s 26us/step - loss: 0.3509 - acc: 0.9565 - val_loss: 0.9351 - val_acc: 0.8464\n",
      "Epoch 46/100\n",
      "125973/125973 [==============================] - 3s 24us/step - loss: 0.3793 - acc: 0.9608 - val_loss: 1.1641 - val_acc: 0.8256\n",
      "Epoch 47/100\n",
      "125973/125973 [==============================] - 3s 25us/step - loss: 0.2994 - acc: 0.9568 - val_loss: 0.8447 - val_acc: 0.8415\n",
      "Epoch 48/100\n",
      "125973/125973 [==============================] - 3s 24us/step - loss: 0.2987 - acc: 0.9613 - val_loss: 1.3385 - val_acc: 0.8245\n",
      "Epoch 49/100\n",
      "125973/125973 [==============================] - 3s 25us/step - loss: 0.3551 - acc: 0.9522 - val_loss: 0.9469 - val_acc: 0.8392\n",
      "Epoch 50/100\n",
      "125973/125973 [==============================] - 3s 26us/step - loss: 0.2881 - acc: 0.9613 - val_loss: 1.0744 - val_acc: 0.8295\n",
      "Epoch 51/100\n",
      "125973/125973 [==============================] - 3s 26us/step - loss: 0.4118 - acc: 0.9599 - val_loss: 0.9485 - val_acc: 0.8420\n",
      "Epoch 52/100\n",
      "125973/125973 [==============================] - 3s 26us/step - loss: 0.3423 - acc: 0.9555 - val_loss: 1.1010 - val_acc: 0.8405\n",
      "Epoch 53/100\n",
      "125973/125973 [==============================] - 3s 26us/step - loss: 0.4338 - acc: 0.9534 - val_loss: 0.9664 - val_acc: 0.8478\n",
      "Epoch 54/100\n",
      "125973/125973 [==============================] - 3s 25us/step - loss: 0.5796 - acc: 0.9585 - val_loss: 1.1640 - val_acc: 0.8323\n",
      "Epoch 55/100\n",
      "125973/125973 [==============================] - 3s 25us/step - loss: 0.3125 - acc: 0.9576 - val_loss: 0.7898 - val_acc: 0.8529\n",
      "Epoch 56/100\n",
      "125973/125973 [==============================] - 3s 25us/step - loss: 0.2450 - acc: 0.9584 - val_loss: 1.1085 - val_acc: 0.8326\n",
      "Epoch 57/100\n",
      "125973/125973 [==============================] - 3s 25us/step - loss: 0.3066 - acc: 0.9598 - val_loss: 1.2404 - val_acc: 0.8314\n",
      "Epoch 58/100\n",
      "125973/125973 [==============================] - 3s 25us/step - loss: 0.4616 - acc: 0.9643 - val_loss: 1.8437 - val_acc: 0.7825\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100\n",
      "125973/125973 [==============================] - 3s 22us/step - loss: 0.7116 - acc: 0.9626 - val_loss: 0.9085 - val_acc: 0.8409\n",
      "Epoch 60/100\n",
      "125973/125973 [==============================] - 3s 22us/step - loss: 0.4110 - acc: 0.9566 - val_loss: 0.7984 - val_acc: 0.8606\n",
      "Epoch 61/100\n",
      "125973/125973 [==============================] - 3s 22us/step - loss: 0.4965 - acc: 0.9629 - val_loss: 0.9371 - val_acc: 0.8359\n",
      "Epoch 62/100\n",
      "125973/125973 [==============================] - 3s 22us/step - loss: 0.2788 - acc: 0.9469 - val_loss: 1.1466 - val_acc: 0.8320\n",
      "Epoch 63/100\n",
      "125973/125973 [==============================] - 3s 22us/step - loss: 0.2721 - acc: 0.9620 - val_loss: 0.9050 - val_acc: 0.8477\n",
      "Epoch 64/100\n",
      "125973/125973 [==============================] - 3s 22us/step - loss: 0.3326 - acc: 0.9606 - val_loss: 1.2717 - val_acc: 0.8302\n",
      "Epoch 65/100\n",
      "125973/125973 [==============================] - 3s 22us/step - loss: 0.5835 - acc: 0.9574 - val_loss: 1.2483 - val_acc: 0.8408\n",
      "Epoch 66/100\n",
      "125973/125973 [==============================] - 3s 22us/step - loss: 0.3442 - acc: 0.9602 - val_loss: 1.5682 - val_acc: 0.7346\n",
      "Epoch 67/100\n",
      "125973/125973 [==============================] - 3s 22us/step - loss: 0.3332 - acc: 0.9517 - val_loss: 1.1398 - val_acc: 0.7806\n",
      "Epoch 68/100\n",
      "125973/125973 [==============================] - 3s 22us/step - loss: 0.3273 - acc: 0.9529 - val_loss: 2.1210 - val_acc: 0.7837\n",
      "Epoch 69/100\n",
      "125973/125973 [==============================] - 3s 22us/step - loss: 0.4229 - acc: 0.9620 - val_loss: 1.1428 - val_acc: 0.8384\n",
      "Epoch 70/100\n",
      "125973/125973 [==============================] - 3s 22us/step - loss: 0.5153 - acc: 0.9531 - val_loss: 0.9888 - val_acc: 0.8155\n",
      "Epoch 71/100\n",
      "125973/125973 [==============================] - 3s 22us/step - loss: 0.3227 - acc: 0.9578 - val_loss: 0.9716 - val_acc: 0.8498\n",
      "Epoch 72/100\n",
      "125973/125973 [==============================] - 3s 22us/step - loss: 0.4415 - acc: 0.9565 - val_loss: 1.0986 - val_acc: 0.8373\n",
      "Epoch 73/100\n",
      "125973/125973 [==============================] - 3s 23us/step - loss: 0.4704 - acc: 0.9570 - val_loss: 1.1420 - val_acc: 0.8472\n",
      "Epoch 74/100\n",
      "125973/125973 [==============================] - 3s 22us/step - loss: 0.6033 - acc: 0.9575 - val_loss: 1.1504 - val_acc: 0.8396\n",
      "Epoch 75/100\n",
      "125973/125973 [==============================] - 3s 22us/step - loss: 0.5869 - acc: 0.9609 - val_loss: 1.1269 - val_acc: 0.8391\n",
      "Epoch 76/100\n",
      "125973/125973 [==============================] - 3s 23us/step - loss: 0.3935 - acc: 0.9531 - val_loss: 0.9925 - val_acc: 0.8394\n",
      "Epoch 77/100\n",
      "125973/125973 [==============================] - 3s 23us/step - loss: 0.4273 - acc: 0.9550 - val_loss: 1.1418 - val_acc: 0.8425\n",
      "Epoch 78/100\n",
      "125973/125973 [==============================] - 3s 22us/step - loss: 0.4240 - acc: 0.9611 - val_loss: 1.2470 - val_acc: 0.8475\n",
      "Epoch 79/100\n",
      "125973/125973 [==============================] - 3s 22us/step - loss: 0.4496 - acc: 0.9658 - val_loss: 0.9419 - val_acc: 0.8537\n",
      "Epoch 80/100\n",
      "125973/125973 [==============================] - 3s 22us/step - loss: 0.3797 - acc: 0.9591 - val_loss: 1.1755 - val_acc: 0.8356\n",
      "Epoch 81/100\n",
      "125973/125973 [==============================] - 3s 22us/step - loss: 0.3647 - acc: 0.9548 - val_loss: 1.1296 - val_acc: 0.8367\n",
      "Epoch 82/100\n",
      "125973/125973 [==============================] - 3s 22us/step - loss: 0.5935 - acc: 0.9564 - val_loss: 0.9796 - val_acc: 0.8404\n",
      "Epoch 83/100\n",
      "125973/125973 [==============================] - 3s 22us/step - loss: 0.4252 - acc: 0.9549 - val_loss: 1.2586 - val_acc: 0.8477\n",
      "Epoch 84/100\n",
      "125973/125973 [==============================] - 3s 22us/step - loss: 0.6569 - acc: 0.9574 - val_loss: 1.2075 - val_acc: 0.8279\n",
      "Epoch 85/100\n",
      "125973/125973 [==============================] - 3s 23us/step - loss: 0.3955 - acc: 0.9545 - val_loss: 0.9996 - val_acc: 0.8486\n",
      "Epoch 86/100\n",
      "125973/125973 [==============================] - 3s 22us/step - loss: 0.2525 - acc: 0.9608 - val_loss: 1.3745 - val_acc: 0.8278\n",
      "Epoch 87/100\n",
      "125973/125973 [==============================] - 3s 23us/step - loss: 0.3444 - acc: 0.9548 - val_loss: 1.1729 - val_acc: 0.8551\n",
      "Epoch 88/100\n",
      "125973/125973 [==============================] - 3s 23us/step - loss: 0.3588 - acc: 0.9605 - val_loss: 1.2063 - val_acc: 0.7917\n",
      "Epoch 89/100\n",
      "125973/125973 [==============================] - 3s 23us/step - loss: 0.5575 - acc: 0.9572 - val_loss: 1.0165 - val_acc: 0.8389\n",
      "Epoch 90/100\n",
      "125973/125973 [==============================] - 3s 23us/step - loss: 0.2883 - acc: 0.9578 - val_loss: 1.2792 - val_acc: 0.7592\n",
      "Epoch 91/100\n",
      "125973/125973 [==============================] - 3s 23us/step - loss: 0.2290 - acc: 0.9608 - val_loss: 1.4066 - val_acc: 0.7913\n",
      "Epoch 92/100\n",
      "125973/125973 [==============================] - 3s 23us/step - loss: 0.4939 - acc: 0.9573 - val_loss: 1.1091 - val_acc: 0.8412\n",
      "Epoch 93/100\n",
      "125973/125973 [==============================] - 3s 23us/step - loss: 0.8263 - acc: 0.9552 - val_loss: 1.1497 - val_acc: 0.7658\n",
      "Epoch 94/100\n",
      "125973/125973 [==============================] - 3s 23us/step - loss: 0.2749 - acc: 0.9574 - val_loss: 0.9579 - val_acc: 0.8479\n",
      "Epoch 95/100\n",
      "125973/125973 [==============================] - 3s 23us/step - loss: 0.2294 - acc: 0.9652 - val_loss: 0.9677 - val_acc: 0.8302\n",
      "Epoch 96/100\n",
      "125973/125973 [==============================] - 3s 23us/step - loss: 0.6365 - acc: 0.9591 - val_loss: 2.1756 - val_acc: 0.7909\n",
      "Epoch 97/100\n",
      "125973/125973 [==============================] - 3s 23us/step - loss: 0.4867 - acc: 0.9567 - val_loss: 1.2938 - val_acc: 0.8395\n",
      "Epoch 98/100\n",
      "125973/125973 [==============================] - 3s 23us/step - loss: 0.3271 - acc: 0.9643 - val_loss: 1.2668 - val_acc: 0.8471\n",
      "Epoch 99/100\n",
      "125973/125973 [==============================] - 3s 23us/step - loss: 0.2309 - acc: 0.9626 - val_loss: 0.9204 - val_acc: 0.8444\n",
      "Epoch 100/100\n",
      "125973/125973 [==============================] - 3s 23us/step - loss: 0.3148 - acc: 0.9586 - val_loss: 0.8625 - val_acc: 0.8548\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d2229ab470>"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_X, train_Y, batch_size=128, nb_epoch=100, validation_data=(test_X, test_Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 2s 42ms/step\n",
      "Accuracy:  0.854817271233\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(test_X, test_Y, verbose=1, steps=50) \n",
    "print(\"Accuracy: \", scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 12s 240ms/step\n",
      "Accuracy:  0.965373516083\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(train_X, train_Y, verbose=1, steps=50) \n",
    "print(\"Accuracy: \", scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
