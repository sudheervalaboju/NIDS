{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Here are some imports that are used along this notebook\n",
    "import math\n",
    "import itertools\n",
    "import pandas\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "import seaborn as sns\n",
    "from time import time\n",
    "import tensorflow as tf\n",
    "from collections import OrderedDict\n",
    "import keras\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.utils import np_utils\n",
    "%matplotlib inline\n",
    "gt0 = time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_nsl_kdd_dataset_path = \"NSL_KDD_Dataset/KDDTrain+.txt\"\n",
    "test_nsl_kdd_dataset_path = \"NSL_KDD_Dataset/KDDTest+.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "col_names = np.array([\"duration\",\"protocol_type\",\"service\",\"flag\",\"src_bytes\",\n",
    "    \"dst_bytes\",\"land\",\"wrong_fragment\",\"urgent\",\"hot\",\"num_failed_logins\",\n",
    "    \"logged_in\",\"num_compromised\",\"root_shell\",\"su_attempted\",\"num_root\",\n",
    "    \"num_file_creations\",\"num_shells\",\"num_access_files\",\"num_outbound_cmds\",\n",
    "    \"is_host_login\",\"is_guest_login\",\"count\",\"srv_count\",\"serror_rate\",\n",
    "    \"srv_serror_rate\",\"rerror_rate\",\"srv_rerror_rate\",\"same_srv_rate\",\n",
    "    \"diff_srv_rate\",\"srv_diff_host_rate\",\"dst_host_count\",\"dst_host_srv_count\",\n",
    "    \"dst_host_same_srv_rate\",\"dst_host_diff_srv_rate\",\"dst_host_same_src_port_rate\",\n",
    "    \"dst_host_srv_diff_host_rate\",\"dst_host_serror_rate\",\"dst_host_srv_serror_rate\",\n",
    "    \"dst_host_rerror_rate\",\"dst_host_srv_rerror_rate\",\"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nominal_inx = [2, 3, 4]\n",
    "binary_inx = [7, 12, 14, 15, 21, 22]\n",
    "numeric_inx = [1, 5, 6, 8, 9, 10, 11, 13, 16, 17, 18, 19, 20, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nominal_cols = []\n",
    "binary_cols = []\n",
    "numeric_cols = []\n",
    "nominal_cols.append(col_names[nominal_inx])\n",
    "binary_cols.append(col_names[binary_inx])\n",
    "numeric_cols.append(col_names[numeric_inx])\n",
    "#print(nominal_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dictionary that contains mapping of various attacks\n",
    "attack_dict_five_class = {\n",
    "    'normal': 'normal',\n",
    "    \n",
    "    'back': 'DoS',\n",
    "    'land': 'DoS',\n",
    "    'neptune': 'DoS',\n",
    "    'pod': 'DoS',\n",
    "    'smurf': 'DoS',\n",
    "    'teardrop': 'DoS',\n",
    "    'mailbomb': 'DoS',\n",
    "    'apache2': 'DoS',\n",
    "    'processtable': 'DoS',\n",
    "    'udpstorm': 'DoS',\n",
    "    \n",
    "    'ipsweep': 'Probe',\n",
    "    'nmap': 'Probe',\n",
    "    'portsweep': 'Probe',\n",
    "    'satan': 'Probe',\n",
    "    'mscan': 'Probe',\n",
    "    'saint': 'Probe',\n",
    "\n",
    "    'ftp_write': 'R2L',\n",
    "    'guess_passwd': 'R2L',\n",
    "    'imap': 'R2L',\n",
    "    'multihop': 'R2L',\n",
    "    'phf': 'R2L',\n",
    "    'spy': 'R2L',\n",
    "    'warezclient': 'R2L',\n",
    "    'warezmaster': 'R2L',\n",
    "    'sendmail': 'R2L',\n",
    "    'named': 'R2L',\n",
    "    'snmpgetattack': 'R2L',\n",
    "    'snmpguess': 'R2L',\n",
    "    'xlock': 'R2L',\n",
    "    'xsnoop': 'R2L',\n",
    "    'worm': 'R2L',\n",
    "    \n",
    "    'buffer_overflow': 'U2R',\n",
    "    'loadmodule': 'U2R',\n",
    "    'perl': 'U2R',\n",
    "    'rootkit': 'U2R',\n",
    "    'httptunnel': 'U2R',\n",
    "    'ps': 'U2R',    \n",
    "    'sqlattack': 'U2R',\n",
    "    'xterm': 'U2R'\n",
    "}\n",
    "\n",
    "attack_two_class = []\n",
    "for key in attack_dict_five_class.keys():\n",
    "    if key == 'normal':\n",
    "        pass\n",
    "    else:\n",
    "        attack_two_class.append(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Load test and train data\n",
    "train_df = pd.read_csv(train_nsl_kdd_dataset_path, names = col_names)\n",
    "test_df  = pd.read_csv(test_nsl_kdd_dataset_path , names = col_names)\n",
    "train_labels = train_df.pop('dst_host_srv_rerror_rate')\n",
    "test_labels = test_df.pop('dst_host_srv_rerror_rate')\n",
    "total_dataset = pd.concat([train_df, test_df])\n",
    "#print(total_dataset.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(148517, 41)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "total_dataset.head()\n",
    "total_dataset.shape\n",
    "#train_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print(pd.get_dummies(train_df, columns=['flag']))\n",
    "#get = train_df.pop('protocol_type')\n",
    "#print(get)\n",
    "#pd.get_dummies(get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#test_df.head(),train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(125973, 122) (22544, 122)\n"
     ]
    }
   ],
   "source": [
    "total_dataset = pd.get_dummies(total_dataset)\n",
    "#print(total_dataset.shape)\n",
    "#train_size = int(len(total_dataset) * 0.80)\n",
    "#print(train_size)\n",
    "#test_size = len(total_dataset) - train_size\n",
    "#print(test_size)\n",
    "train_df = total_dataset.iloc[0:125973, :]\n",
    "test_df = total_dataset.iloc[125973:, :]\n",
    "print(train_df.shape, test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#total_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_labels_for_two_class = pd.DataFrame(train_labels.as_matrix(), columns=[\"class\"])\n",
    "#print(train_labels_for_two_class)\n",
    "test_labels_for_two_class = pd.DataFrame(test_labels.as_matrix(), columns=[\"class\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_labels_for_two_class.loc[train_labels_for_two_class['class'].isin(attack_two_class) , 'class'] = 1\n",
    "train_labels_for_two_class.loc[train_labels_for_two_class['class'] == \"normal\" , 'class'] = 0\n",
    "#print(train_labels_for_two_class)\n",
    "#for test labels \n",
    "test_labels_for_two_class.loc[test_labels_for_two_class['class'].isin(attack_two_class) , 'class'] = 1\n",
    "test_labels_for_two_class.loc[test_labels_for_two_class['class'] == \"normal\" , 'class'] = 0\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(125973, 2)\n",
      "(125973, 2)\n"
     ]
    }
   ],
   "source": [
    "train_labels_for_two_class = np_utils.to_categorical(train_labels_for_two_class)\n",
    "print(train_labels_for_two_class.shape)\n",
    "test_labels_for_two_class = np_utils.to_categorical(test_labels_for_two_class)\n",
    "print(train_labels_for_two_class.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 1.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  1.],\n",
       "       [ 1.,  0.],\n",
       "       [ 0.,  1.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#min-max mazimazation for the data\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "train_X = train_df.as_matrix()\n",
    "train_Y = train_labels_for_two_class\n",
    "\n",
    "test_X = test_df.as_matrix()\n",
    "test_Y = test_labels_for_two_class\n",
    "scaler = MinMaxScaler() \n",
    "scaler.fit_transform(train_X)\n",
    "scaler.fit_transform(train_Y)\n",
    "scaler.fit_transform(test_X)\n",
    "scaler.fit_transform(test_Y)\n",
    "#train_X.shape[1]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Training our auto encoder\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, Dense\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from keras import regularizers\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_dim = train_X.shape[1]\n",
    "input_layer = Input(shape=(input_dim, ))\n",
    "encoder = Dense(30, activation=\"sigmoid\", \n",
    "                activity_regularizer=regularizers.l1(10e-5))(input_layer)\n",
    "decoder = Dense(input_dim, activation='relu')(encoder)\n",
    "autoencoder = Model(inputs=input_layer, outputs=decoder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 125973 samples, validate on 22544 samples\n",
      "Epoch 1/100\n",
      "125973/125973 [==============================] - 4s 32us/step - loss: 415028270365.6467 - acc: 0.4381 - val_loss: 1836705026.0524 - val_acc: 0.3403\n",
      "Epoch 2/100\n",
      "125973/125973 [==============================] - 4s 29us/step - loss: 415028262838.6712 - acc: 0.4300 - val_loss: 1836704481.4977 - val_acc: 0.3495\n",
      "Epoch 3/100\n",
      "125973/125973 [==============================] - 4s 30us/step - loss: 415028269559.5952 - acc: 0.4338 - val_loss: 1836704062.6548 - val_acc: 0.3507\n",
      "Epoch 4/100\n",
      "125973/125973 [==============================] - 4s 30us/step - loss: 415028266130.7554 - acc: 0.4399 - val_loss: 1836703546.7452 - val_acc: 0.3514\n",
      "Epoch 5/100\n",
      "125973/125973 [==============================] - 4s 30us/step - loss: 415028260773.6081 - acc: 0.4454 - val_loss: 1836703113.3909 - val_acc: 0.3677\n",
      "Epoch 6/100\n",
      "125973/125973 [==============================] - 4s 30us/step - loss: 415028257396.9452 - acc: 0.4410 - val_loss: 1836702697.3674 - val_acc: 0.3577\n",
      "Epoch 7/100\n",
      "125973/125973 [==============================] - 4s 30us/step - loss: 415028260599.2947 - acc: 0.4379 - val_loss: 1836702168.9088 - val_acc: 0.3588\n",
      "Epoch 8/100\n",
      "125973/125973 [==============================] - 4s 30us/step - loss: 415028257291.6493 - acc: 0.4407 - val_loss: 1836701600.2995 - val_acc: 0.3571\n",
      "Epoch 9/100\n",
      "125973/125973 [==============================] - 4s 30us/step - loss: 415028266315.2119 - acc: 0.4447 - val_loss: 1836701252.3645 - val_acc: 0.3674\n",
      "Epoch 10/100\n",
      "125973/125973 [==============================] - 4s 30us/step - loss: 415028263072.0687 - acc: 0.4482 - val_loss: 1836700670.7228 - val_acc: 0.3683\n",
      "Epoch 11/100\n",
      "125973/125973 [==============================] - 4s 30us/step - loss: 415028234363.2374 - acc: 0.4509 - val_loss: 1836700285.5370 - val_acc: 0.3772\n",
      "Epoch 12/100\n",
      "125973/125973 [==============================] - 4s 30us/step - loss: 415028237274.5905 - acc: 0.4527 - val_loss: 1836699654.1554 - val_acc: 0.3766\n",
      "Epoch 13/100\n",
      "125973/125973 [==============================] - 4s 30us/step - loss: 415028222900.2458 - acc: 0.4533 - val_loss: 1836699137.9385 - val_acc: 0.3774\n",
      "Epoch 14/100\n",
      "125973/125973 [==============================] - 4s 30us/step - loss: 415028219824.9828 - acc: 0.4547 - val_loss: 1836698717.6760 - val_acc: 0.3996\n",
      "Epoch 15/100\n",
      "125973/125973 [==============================] - 4s 30us/step - loss: 415028221555.6245 - acc: 0.4568 - val_loss: 1836698178.5534 - val_acc: 0.3994\n",
      "Epoch 16/100\n",
      "125973/125973 [==============================] - 4s 30us/step - loss: 415028222408.1181 - acc: 0.4596 - val_loss: 1836697642.9191 - val_acc: 0.4092\n",
      "Epoch 17/100\n",
      "125973/125973 [==============================] - 4s 30us/step - loss: 415028225897.9156 - acc: 0.4721 - val_loss: 1836697235.3657 - val_acc: 0.4396\n",
      "Epoch 18/100\n",
      "125973/125973 [==============================] - 4s 30us/step - loss: 415028215368.0356 - acc: 0.5126 - val_loss: 1836696796.3542 - val_acc: 0.4703\n",
      "Epoch 19/100\n",
      "125973/125973 [==============================] - 4s 32us/step - loss: 415028221388.8199 - acc: 0.5267 - val_loss: 1836696463.5091 - val_acc: 0.4701\n",
      "Epoch 20/100\n",
      "125973/125973 [==============================] - 4s 32us/step - loss: 415028215338.9557 - acc: 0.5275 - val_loss: 1836695921.9756 - val_acc: 0.4637\n",
      "Epoch 21/100\n",
      "125973/125973 [==============================] - 4s 31us/step - loss: 415028214613.5876 - acc: 0.5256 - val_loss: 1836695326.8518 - val_acc: 0.4689\n",
      "Epoch 22/100\n",
      "125973/125973 [==============================] - 4s 30us/step - loss: 415028210397.6715 - acc: 0.5254 - val_loss: 1836694978.8209 - val_acc: 0.4696\n",
      "Epoch 23/100\n",
      "125973/125973 [==============================] - 4s 30us/step - loss: 415028212681.4102 - acc: 0.5265 - val_loss: 1836694419.9634 - val_acc: 0.4697\n",
      "Epoch 24/100\n",
      "125973/125973 [==============================] - 4s 31us/step - loss: 415028208098.7007 - acc: 0.5281 - val_loss: 1836693814.3092 - val_acc: 0.4854\n",
      "Epoch 25/100\n",
      "125973/125973 [==============================] - 4s 30us/step - loss: 415028213269.9321 - acc: 0.5269 - val_loss: 1836693455.1290 - val_acc: 0.4930\n",
      "Epoch 26/100\n",
      "125973/125973 [==============================] - 4s 31us/step - loss: 415028211392.4557 - acc: 0.5226 - val_loss: 1836692958.7366 - val_acc: 0.4901\n",
      "Epoch 27/100\n",
      "125973/125973 [==============================] - 4s 31us/step - loss: 415028208873.8753 - acc: 0.5239 - val_loss: 1836692428.0672 - val_acc: 0.4982\n",
      "Epoch 28/100\n",
      "125973/125973 [==============================] - 4s 31us/step - loss: 415028203452.1994 - acc: 0.5316 - val_loss: 1836692014.0546 - val_acc: 0.4988\n",
      "Epoch 29/100\n",
      "125973/125973 [==============================] - 4s 31us/step - loss: 415028203471.7100 - acc: 0.5343 - val_loss: 1836691397.8534 - val_acc: 0.4974\n",
      "Epoch 30/100\n",
      "125973/125973 [==============================] - 4s 31us/step - loss: 415028206411.4197 - acc: 0.5422 - val_loss: 1836690947.2504 - val_acc: 0.5027\n",
      "Epoch 31/100\n",
      "125973/125973 [==============================] - 4s 34us/step - loss: 415028205929.7029 - acc: 0.5470 - val_loss: 1836690578.4248 - val_acc: 0.5057\n",
      "Epoch 32/100\n",
      "125973/125973 [==============================] - 4s 33us/step - loss: 415028199987.2018 - acc: 0.5493 - val_loss: 1836689956.4879 - val_acc: 0.5086\n",
      "Epoch 33/100\n",
      "125973/125973 [==============================] - 4s 31us/step - loss: 415028202958.1349 - acc: 0.5498 - val_loss: 1836689632.5090 - val_acc: 0.5055\n",
      "Epoch 34/100\n",
      "125973/125973 [==============================] - 4s 31us/step - loss: 415028207801.2626 - acc: 0.5494 - val_loss: 1836689096.9035 - val_acc: 0.4997\n",
      "Epoch 35/100\n",
      "125973/125973 [==============================] - 4s 30us/step - loss: 415028202518.4596 - acc: 0.5460 - val_loss: 1836688502.1408 - val_acc: 0.5051\n",
      "Epoch 36/100\n",
      "125973/125973 [==============================] - 4s 31us/step - loss: 415028203954.2449 - acc: 0.5422 - val_loss: 1836688157.0923 - val_acc: 0.4948\n",
      "Epoch 37/100\n",
      "125973/125973 [==============================] - 4s 31us/step - loss: 415028198199.4254 - acc: 0.5384 - val_loss: 1836687601.3082 - val_acc: 0.4951\n",
      "Epoch 38/100\n",
      "125973/125973 [==============================] - 4s 30us/step - loss: 415028184976.0418 - acc: 0.5362 - val_loss: 1836687051.9951 - val_acc: 0.4969\n",
      "Epoch 39/100\n",
      "125973/125973 [==============================] - 4s 31us/step - loss: 415028191952.0344 - acc: 0.5349 - val_loss: 1836686630.1999 - val_acc: 0.4976\n",
      "Epoch 40/100\n",
      "125973/125973 [==============================] - 4s 31us/step - loss: 415028181802.5207 - acc: 0.5334 - val_loss: 1836686096.9509 - val_acc: 0.4860\n",
      "Epoch 41/100\n",
      "125973/125973 [==============================] - 4s 30us/step - loss: 415028184844.6448 - acc: 0.5368 - val_loss: 1836685573.1835 - val_acc: 0.4913\n",
      "Epoch 42/100\n",
      "125973/125973 [==============================] - 4s 33us/step - loss: 415028186408.6031 - acc: 0.5384 - val_loss: 1836685160.9745 - val_acc: 0.4929\n",
      "Epoch 43/100\n",
      "125973/125973 [==============================] - 4s 32us/step - loss: 415028180545.0682 - acc: 0.5402 - val_loss: 1836684721.9514 - val_acc: 0.4906\n",
      "Epoch 44/100\n",
      "125973/125973 [==============================] - 4s 31us/step - loss: 415028183008.6495 - acc: 0.5425 - val_loss: 1836684170.4706 - val_acc: 0.4987\n",
      "Epoch 45/100\n",
      "125973/125973 [==============================] - 4s 31us/step - loss: 415028182213.0771 - acc: 0.5440 - val_loss: 1836683820.9092 - val_acc: 0.4895\n",
      "Epoch 46/100\n",
      "125973/125973 [==============================] - 4s 31us/step - loss: 415028176444.9205 - acc: 0.5452 - val_loss: 1836683148.6223 - val_acc: 0.4982\n",
      "Epoch 47/100\n",
      "125973/125973 [==============================] - 4s 31us/step - loss: 415028180136.6875 - acc: 0.5480 - val_loss: 1836682826.3343 - val_acc: 0.4941\n",
      "Epoch 48/100\n",
      "125973/125973 [==============================] - 4s 31us/step - loss: 415028184402.1891 - acc: 0.5496 - val_loss: 1836682293.7884 - val_acc: 0.4946\n",
      "Epoch 49/100\n",
      "125973/125973 [==============================] - 4s 31us/step - loss: 415028179811.4819 - acc: 0.5527 - val_loss: 1836681728.0379 - val_acc: 0.4959\n",
      "Epoch 50/100\n",
      "125973/125973 [==============================] - 4s 32us/step - loss: 415028145669.8670 - acc: 0.5562 - val_loss: 1836681321.1655 - val_acc: 0.5006\n",
      "Epoch 51/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125973/125973 [==============================] - 4s 30us/step - loss: 415028152250.9122 - acc: 0.5593 - val_loss: 1836680782.4237 - val_acc: 0.4998\n",
      "Epoch 52/100\n",
      "125973/125973 [==============================] - 4s 30us/step - loss: 415028143441.5607 - acc: 0.5613 - val_loss: 1836680234.6390 - val_acc: 0.4931\n",
      "Epoch 53/100\n",
      "125973/125973 [==============================] - 4s 32us/step - loss: 415028145894.7603 - acc: 0.5641 - val_loss: 1836679842.4194 - val_acc: 0.5162\n",
      "Epoch 54/100\n",
      "125973/125973 [==============================] - 4s 32us/step - loss: 415028142914.8621 - acc: 0.6152 - val_loss: 1836679324.2453 - val_acc: 0.5976\n",
      "Epoch 55/100\n",
      "125973/125973 [==============================] - 4s 30us/step - loss: 415028142921.3212 - acc: 0.6356 - val_loss: 1836678876.3441 - val_acc: 0.6005\n",
      "Epoch 56/100\n",
      "125973/125973 [==============================] - 4s 30us/step - loss: 415028143091.8494 - acc: 0.6352 - val_loss: 1836678515.0388 - val_acc: 0.5866\n",
      "Epoch 57/100\n",
      "125973/125973 [==============================] - 4s 30us/step - loss: 415028144433.9348 - acc: 0.6345 - val_loss: 1836677928.5031 - val_acc: 0.5892\n",
      "Epoch 58/100\n",
      "125973/125973 [==============================] - 4s 30us/step - loss: 415028137024.7172 - acc: 0.6356 - val_loss: 1836677377.0458 - val_acc: 0.5938\n",
      "Epoch 59/100\n",
      "125973/125973 [==============================] - 4s 30us/step - loss: 415028142199.7903 - acc: 0.6377 - val_loss: 1836677016.0828 - val_acc: 0.5723\n",
      "Epoch 60/100\n",
      "125973/125973 [==============================] - 4s 30us/step - loss: 415028135203.0693 - acc: 0.6378 - val_loss: 1836676471.0126 - val_acc: 0.5763\n",
      "Epoch 61/100\n",
      "125973/125973 [==============================] - 4s 30us/step - loss: 415028142573.7420 - acc: 0.6396 - val_loss: 1836676122.3481 - val_acc: 0.5876\n",
      "Epoch 62/100\n",
      "125973/125973 [==============================] - 4s 30us/step - loss: 415028138579.6512 - acc: 0.6411 - val_loss: 1836675504.4182 - val_acc: 0.5879\n",
      "Epoch 63/100\n",
      "125973/125973 [==============================] - 4s 30us/step - loss: 415028119689.3134 - acc: 0.6423 - val_loss: 1836674964.9015 - val_acc: 0.5786\n",
      "Epoch 64/100\n",
      "125973/125973 [==============================] - 4s 30us/step - loss: 415028116491.6836 - acc: 0.6432 - val_loss: 1836674572.0645 - val_acc: 0.5801\n",
      "Epoch 65/100\n",
      "125973/125973 [==============================] - 4s 30us/step - loss: 415028124065.5125 - acc: 0.6424 - val_loss: 1836673977.4408 - val_acc: 0.5784\n",
      "Epoch 66/100\n",
      "125973/125973 [==============================] - 4s 30us/step - loss: 415028118109.1478 - acc: 0.6434 - val_loss: 1836673454.9905 - val_acc: 0.5805\n",
      "Epoch 67/100\n",
      "125973/125973 [==============================] - 4s 30us/step - loss: 415028121253.8709 - acc: 0.6439 - val_loss: 1836673114.2835 - val_acc: 0.6014\n",
      "Epoch 68/100\n",
      "125973/125973 [==============================] - 4s 30us/step - loss: 415028119562.3715 - acc: 0.6444 - val_loss: 1836672636.1504 - val_acc: 0.5981\n",
      "Epoch 69/100\n",
      "125973/125973 [==============================] - 4s 30us/step - loss: 415028122864.7970 - acc: 0.6447 - val_loss: 1836672077.6452 - val_acc: 0.5938\n",
      "Epoch 70/100\n",
      "125973/125973 [==============================] - 4s 30us/step - loss: 415028119542.7063 - acc: 0.6456 - val_loss: 1836671738.6324 - val_acc: 0.5914\n",
      "Epoch 71/100\n",
      "125973/125973 [==============================] - 4s 30us/step - loss: 415028120865.6722 - acc: 0.6430 - val_loss: 1836671160.7150 - val_acc: 0.5993\n",
      "Epoch 72/100\n",
      "125973/125973 [==============================] - 4s 30us/step - loss: 415028112616.5593 - acc: 0.6434 - val_loss: 1836670827.4912 - val_acc: 0.6020\n",
      "Epoch 73/100\n",
      "125973/125973 [==============================] - 4s 30us/step - loss: 415028111493.9680 - acc: 0.6427 - val_loss: 1836670284.6891 - val_acc: 0.5951\n",
      "Epoch 74/100\n",
      "125973/125973 [==============================] - 4s 30us/step - loss: 415028123771.6782 - acc: 0.6393 - val_loss: 1836669718.9535 - val_acc: 0.5951\n",
      "Epoch 75/100\n",
      "125973/125973 [==============================] - 4s 30us/step - loss: 415028117554.6753 - acc: 0.6396 - val_loss: 1836669346.3741 - val_acc: 0.5972\n",
      "Epoch 76/100\n",
      "125973/125973 [==============================] - 4s 30us/step - loss: 415028115856.3902 - acc: 0.6390 - val_loss: 1836668819.0701 - val_acc: 0.6013\n",
      "Epoch 77/100\n",
      "125973/125973 [==============================] - 4s 30us/step - loss: 415028117637.8530 - acc: 0.6394 - val_loss: 1836668285.6770 - val_acc: 0.5928\n",
      "Epoch 78/100\n",
      "125973/125973 [==============================] - 4s 30us/step - loss: 415028115658.8636 - acc: 0.6426 - val_loss: 1836667878.4344 - val_acc: 0.6049\n",
      "Epoch 79/100\n",
      "125973/125973 [==============================] - 4s 30us/step - loss: 415028108253.1946 - acc: 0.6422 - val_loss: 1836667441.1198 - val_acc: 0.5925\n",
      "Epoch 80/100\n",
      "125973/125973 [==============================] - 4s 30us/step - loss: 415028107546.4899 - acc: 0.6412 - val_loss: 1836666793.8068 - val_acc: 0.6068\n",
      "Epoch 81/100\n",
      "125973/125973 [==============================] - 4s 30us/step - loss: 415028113470.9092 - acc: 0.6423 - val_loss: 1836666476.0868 - val_acc: 0.6114\n",
      "Epoch 82/100\n",
      "125973/125973 [==============================] - 4s 30us/step - loss: 415028113705.7028 - acc: 0.6456 - val_loss: 1836665878.6045 - val_acc: 0.6136\n",
      "Epoch 83/100\n",
      "125973/125973 [==============================] - 4s 30us/step - loss: 415028104555.3649 - acc: 0.6447 - val_loss: 1836665316.1079 - val_acc: 0.6178\n",
      "Epoch 84/100\n",
      "125973/125973 [==============================] - 4s 30us/step - loss: 415028103570.0445 - acc: 0.6443 - val_loss: 1836664946.5755 - val_acc: 0.6089\n",
      "Epoch 85/100\n",
      "125973/125973 [==============================] - 4s 30us/step - loss: 415028106612.1122 - acc: 0.6443 - val_loss: 1836664439.0579 - val_acc: 0.6238\n",
      "Epoch 86/100\n",
      "125973/125973 [==============================] - 4s 30us/step - loss: 415028109778.8099 - acc: 0.6453 - val_loss: 1836664039.5435 - val_acc: 0.6109\n",
      "Epoch 87/100\n",
      "125973/125973 [==============================] - 4s 32us/step - loss: 415028105641.8463 - acc: 0.6452 - val_loss: 1836663506.0325 - val_acc: 0.6136\n",
      "Epoch 88/100\n",
      "125973/125973 [==============================] - 4s 32us/step - loss: 415028092360.0778 - acc: 0.6465 - val_loss: 1836662991.4301 - val_acc: 0.6211\n",
      "Epoch 89/100\n",
      "125973/125973 [==============================] - 4s 30us/step - loss: 415028087502.9368 - acc: 0.6473 - val_loss: 1836662656.5463 - val_acc: 0.6011\n",
      "Epoch 90/100\n",
      "125973/125973 [==============================] - 4s 30us/step - loss: 415028094132.5568 - acc: 0.6484 - val_loss: 1836662018.2386 - val_acc: 0.6193\n",
      "Epoch 91/100\n",
      "125973/125973 [==============================] - 4s 30us/step - loss: 415028087729.6100 - acc: 0.6481 - val_loss: 1836661595.7404 - val_acc: 0.6075\n",
      "Epoch 92/100\n",
      "125973/125973 [==============================] - 4s 30us/step - loss: 415028085031.5865 - acc: 0.6478 - val_loss: 1836661222.8356 - val_acc: 0.6156\n",
      "Epoch 93/100\n",
      "125973/125973 [==============================] - 4s 30us/step - loss: 415028089983.9570 - acc: 0.6474 - val_loss: 1836660639.4719 - val_acc: 0.6077\n",
      "Epoch 94/100\n",
      "125973/125973 [==============================] - 4s 30us/step - loss: 415028069317.3115 - acc: 0.6477 - val_loss: 1836660107.7539 - val_acc: 0.6124\n",
      "Epoch 95/100\n",
      "125973/125973 [==============================] - 4s 31us/step - loss: 415028069190.5226 - acc: 0.6476 - val_loss: 1836659805.4242 - val_acc: 0.6069\n",
      "Epoch 96/100\n",
      "125973/125973 [==============================] - 4s 31us/step - loss: 415028066208.5638 - acc: 0.6496 - val_loss: 1836659101.4514 - val_acc: 0.6153\n",
      "Epoch 97/100\n",
      "125973/125973 [==============================] - 4s 30us/step - loss: 415028075467.5624 - acc: 0.6509 - val_loss: 1836658755.5599 - val_acc: 0.6222\n",
      "Epoch 98/100\n",
      "125973/125973 [==============================] - 4s 33us/step - loss: 415028067771.8406 - acc: 0.6514 - val_loss: 1836658223.5587 - val_acc: 0.6032\n",
      "Epoch 99/100\n",
      "125973/125973 [==============================] - 4s 32us/step - loss: 415028065203.4805 - acc: 0.6515 - val_loss: 1836657610.1806 - val_acc: 0.6193\n",
      "Epoch 100/100\n",
      "125973/125973 [==============================] - 4s 31us/step - loss: 415028039711.1761 - acc: 0.6510 - val_loss: 1836657288.0634 - val_acc: 0.6116\n"
     ]
    }
   ],
   "source": [
    "nb_epoch = 100\n",
    "batch_size = 128\n",
    "autoencoder.compile(optimizer='adam', \n",
    "                    loss='mean_squared_error', \n",
    "                    metrics=['accuracy'])\n",
    "checkpointer = ModelCheckpoint(filepath=\"model.h5\",\n",
    "                               verbose=0,\n",
    "                               save_best_only=True)\n",
    "\n",
    "history = autoencoder.fit(train_X,train_X ,\n",
    "                    epochs=nb_epoch,\n",
    "                    verbose = 1,\n",
    "                    batch_size=batch_size,\n",
    "                    shuffle=True,\n",
    "                    validation_data=(test_X, test_X)).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder = Model(input_layer, encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out2 = Dense(2, activation='softmax')(encoder.output)\n",
    "newmodel = Model(encoder.input,out2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22544, 122)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 125973 samples, validate on 22544 samples\n",
      "Epoch 1/100\n",
      "125973/125973 [==============================] - 3s 21us/step - loss: 0.9443 - acc: 0.4492 - val_loss: 0.8440 - val_acc: 0.7714\n",
      "Epoch 2/100\n",
      "125973/125973 [==============================] - 2s 19us/step - loss: 0.7766 - acc: 0.7663 - val_loss: 0.7847 - val_acc: 0.7764\n",
      "Epoch 3/100\n",
      "125973/125973 [==============================] - 2s 20us/step - loss: 0.7133 - acc: 0.8404 - val_loss: 0.7838 - val_acc: 0.7279\n",
      "Epoch 4/100\n",
      "125973/125973 [==============================] - 3s 21us/step - loss: 0.6784 - acc: 0.8778 - val_loss: 0.7628 - val_acc: 0.7232\n",
      "Epoch 5/100\n",
      "125973/125973 [==============================] - 3s 20us/step - loss: 0.6176 - acc: 0.8925 - val_loss: 0.7367 - val_acc: 0.7203\n",
      "Epoch 6/100\n",
      "125973/125973 [==============================] - 3s 21us/step - loss: 0.6043 - acc: 0.9015 - val_loss: 0.7514 - val_acc: 0.7187\n",
      "Epoch 7/100\n",
      "125973/125973 [==============================] - 3s 23us/step - loss: 0.5949 - acc: 0.9105 - val_loss: 0.7513 - val_acc: 0.7208\n",
      "Epoch 8/100\n",
      "125973/125973 [==============================] - 3s 20us/step - loss: 0.5890 - acc: 0.9161 - val_loss: 0.7518 - val_acc: 0.7213\n",
      "Epoch 9/100\n",
      "125973/125973 [==============================] - 3s 21us/step - loss: 0.5836 - acc: 0.9191 - val_loss: 0.7509 - val_acc: 0.7224\n",
      "Epoch 10/100\n",
      "125973/125973 [==============================] - 3s 21us/step - loss: 0.5776 - acc: 0.9203 - val_loss: 0.7501 - val_acc: 0.7230\n",
      "Epoch 11/100\n",
      "125973/125973 [==============================] - 3s 20us/step - loss: 0.5702 - acc: 0.9211 - val_loss: 0.7471 - val_acc: 0.7238\n",
      "Epoch 12/100\n",
      "125973/125973 [==============================] - 3s 22us/step - loss: 0.5639 - acc: 0.9218 - val_loss: 0.7450 - val_acc: 0.7243\n",
      "Epoch 13/100\n",
      "125973/125973 [==============================] - 3s 21us/step - loss: 0.5558 - acc: 0.9224 - val_loss: 0.7380 - val_acc: 0.7257\n",
      "Epoch 14/100\n",
      "125973/125973 [==============================] - 3s 21us/step - loss: 0.5475 - acc: 0.9227 - val_loss: 0.7370 - val_acc: 0.7260\n",
      "Epoch 15/100\n",
      "125973/125973 [==============================] - 3s 21us/step - loss: 0.5448 - acc: 0.9229 - val_loss: 0.7607 - val_acc: 0.7289\n",
      "Epoch 16/100\n",
      "125973/125973 [==============================] - 3s 21us/step - loss: 0.5365 - acc: 0.9224 - val_loss: 0.7511 - val_acc: 0.7347\n",
      "Epoch 17/100\n",
      "125973/125973 [==============================] - 2s 20us/step - loss: 0.5239 - acc: 0.9218 - val_loss: 0.7386 - val_acc: 0.7436\n",
      "Epoch 18/100\n",
      "125973/125973 [==============================] - 2s 20us/step - loss: 0.5138 - acc: 0.9259 - val_loss: 0.7356 - val_acc: 0.7431\n",
      "Epoch 19/100\n",
      "125973/125973 [==============================] - 3s 20us/step - loss: 0.5096 - acc: 0.9267 - val_loss: 0.7362 - val_acc: 0.7401\n",
      "Epoch 20/100\n",
      "125973/125973 [==============================] - 3s 21us/step - loss: 0.5060 - acc: 0.9272 - val_loss: 0.7368 - val_acc: 0.7389\n",
      "Epoch 21/100\n",
      "125973/125973 [==============================] - 2s 20us/step - loss: 0.5029 - acc: 0.9276 - val_loss: 0.7388 - val_acc: 0.7375\n",
      "Epoch 22/100\n",
      "125973/125973 [==============================] - 3s 21us/step - loss: 0.5002 - acc: 0.9279 - val_loss: 0.7427 - val_acc: 0.7372\n",
      "Epoch 23/100\n",
      "125973/125973 [==============================] - 3s 21us/step - loss: 0.4969 - acc: 0.9282 - val_loss: 0.7452 - val_acc: 0.7373\n",
      "Epoch 24/100\n",
      "125973/125973 [==============================] - 3s 20us/step - loss: 0.4936 - acc: 0.9284 - val_loss: 0.7481 - val_acc: 0.7375\n",
      "Epoch 25/100\n",
      "125973/125973 [==============================] - 2s 18us/step - loss: 0.4902 - acc: 0.9287 - val_loss: 0.7500 - val_acc: 0.7378\n",
      "Epoch 26/100\n",
      "125973/125973 [==============================] - 2s 17us/step - loss: 0.4861 - acc: 0.9289 - val_loss: 0.7504 - val_acc: 0.7380\n",
      "Epoch 27/100\n",
      "125973/125973 [==============================] - 2s 19us/step - loss: 0.4783 - acc: 0.9291 - val_loss: 0.7452 - val_acc: 0.7385\n",
      "Epoch 28/100\n",
      "125973/125973 [==============================] - 3s 20us/step - loss: 0.4731 - acc: 0.9294 - val_loss: 0.7469 - val_acc: 0.7404\n",
      "Epoch 29/100\n",
      "125973/125973 [==============================] - 3s 20us/step - loss: 0.4687 - acc: 0.9299 - val_loss: 0.7207 - val_acc: 0.7417\n",
      "Epoch 30/100\n",
      "125973/125973 [==============================] - 2s 17us/step - loss: 0.4657 - acc: 0.9302 - val_loss: 0.7224 - val_acc: 0.7439\n",
      "Epoch 31/100\n",
      "125973/125973 [==============================] - 2s 17us/step - loss: 0.4640 - acc: 0.9312 - val_loss: 0.7234 - val_acc: 0.7447\n",
      "Epoch 32/100\n",
      "125973/125973 [==============================] - 2s 17us/step - loss: 0.4620 - acc: 0.9327 - val_loss: 0.7250 - val_acc: 0.7452\n",
      "Epoch 33/100\n",
      "125973/125973 [==============================] - 2s 17us/step - loss: 0.4601 - acc: 0.9351 - val_loss: 0.7262 - val_acc: 0.7457\n",
      "Epoch 34/100\n",
      "125973/125973 [==============================] - 2s 17us/step - loss: 0.4583 - acc: 0.9375 - val_loss: 0.7274 - val_acc: 0.7462\n",
      "Epoch 35/100\n",
      "125973/125973 [==============================] - 2s 17us/step - loss: 0.4565 - acc: 0.9385 - val_loss: 0.7292 - val_acc: 0.7465\n",
      "Epoch 36/100\n",
      "125973/125973 [==============================] - 2s 17us/step - loss: 0.4549 - acc: 0.9395 - val_loss: 0.7303 - val_acc: 0.7468\n",
      "Epoch 37/100\n",
      "125973/125973 [==============================] - 2s 17us/step - loss: 0.4534 - acc: 0.9405 - val_loss: 0.7317 - val_acc: 0.7468\n",
      "Epoch 38/100\n",
      "125973/125973 [==============================] - 2s 17us/step - loss: 0.4520 - acc: 0.9408 - val_loss: 0.7330 - val_acc: 0.7469\n",
      "Epoch 39/100\n",
      "125973/125973 [==============================] - 2s 17us/step - loss: 0.4507 - acc: 0.9413 - val_loss: 0.7343 - val_acc: 0.7472\n",
      "Epoch 40/100\n",
      "125973/125973 [==============================] - 2s 18us/step - loss: 0.4493 - acc: 0.9417 - val_loss: 0.7355 - val_acc: 0.7476\n",
      "Epoch 41/100\n",
      "125973/125973 [==============================] - 2s 17us/step - loss: 0.4481 - acc: 0.9418 - val_loss: 0.7369 - val_acc: 0.7479\n",
      "Epoch 42/100\n",
      "125973/125973 [==============================] - 2s 17us/step - loss: 0.4468 - acc: 0.9419 - val_loss: 0.7378 - val_acc: 0.7481\n",
      "Epoch 43/100\n",
      "125973/125973 [==============================] - 2s 17us/step - loss: 0.4455 - acc: 0.9419 - val_loss: 0.7398 - val_acc: 0.7480\n",
      "Epoch 44/100\n",
      "125973/125973 [==============================] - 2s 17us/step - loss: 0.4443 - acc: 0.9420 - val_loss: 0.7416 - val_acc: 0.7481\n",
      "Epoch 45/100\n",
      "125973/125973 [==============================] - 2s 17us/step - loss: 0.4431 - acc: 0.9420 - val_loss: 0.7435 - val_acc: 0.7480\n",
      "Epoch 46/100\n",
      "125973/125973 [==============================] - 2s 17us/step - loss: 0.4421 - acc: 0.9420 - val_loss: 0.7435 - val_acc: 0.7482\n",
      "Epoch 47/100\n",
      "125973/125973 [==============================] - 2s 17us/step - loss: 0.4409 - acc: 0.9420 - val_loss: 0.7450 - val_acc: 0.7484\n",
      "Epoch 48/100\n",
      "125973/125973 [==============================] - 2s 17us/step - loss: 0.4397 - acc: 0.9420 - val_loss: 0.7464 - val_acc: 0.7486\n",
      "Epoch 49/100\n",
      "125973/125973 [==============================] - 2s 17us/step - loss: 0.4386 - acc: 0.9421 - val_loss: 0.7474 - val_acc: 0.7488\n",
      "Epoch 50/100\n",
      "125973/125973 [==============================] - 2s 17us/step - loss: 0.4375 - acc: 0.9422 - val_loss: 0.7491 - val_acc: 0.7487\n",
      "Epoch 51/100\n",
      "125973/125973 [==============================] - 2s 17us/step - loss: 0.4363 - acc: 0.9422 - val_loss: 0.7503 - val_acc: 0.7485\n",
      "Epoch 52/100\n",
      "125973/125973 [==============================] - 2s 17us/step - loss: 0.4351 - acc: 0.9421 - val_loss: 0.7517 - val_acc: 0.7484\n",
      "Epoch 53/100\n",
      "125973/125973 [==============================] - 2s 17us/step - loss: 0.4340 - acc: 0.9423 - val_loss: 0.7533 - val_acc: 0.7484\n",
      "Epoch 54/100\n",
      "125973/125973 [==============================] - 2s 17us/step - loss: 0.4331 - acc: 0.9425 - val_loss: 0.7558 - val_acc: 0.7483\n",
      "Epoch 55/100\n",
      "125973/125973 [==============================] - 2s 17us/step - loss: 0.4321 - acc: 0.9426 - val_loss: 0.7561 - val_acc: 0.7483\n",
      "Epoch 56/100\n",
      "125973/125973 [==============================] - 2s 17us/step - loss: 0.4312 - acc: 0.9428 - val_loss: 0.7569 - val_acc: 0.7484\n",
      "Epoch 57/100\n",
      "125973/125973 [==============================] - 2s 17us/step - loss: 0.4302 - acc: 0.9429 - val_loss: 0.7589 - val_acc: 0.7482\n",
      "Epoch 58/100\n",
      "125973/125973 [==============================] - 2s 17us/step - loss: 0.4293 - acc: 0.9429 - val_loss: 0.7594 - val_acc: 0.7483\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100\n",
      "125973/125973 [==============================] - 2s 17us/step - loss: 0.4284 - acc: 0.9431 - val_loss: 0.7619 - val_acc: 0.7480\n",
      "Epoch 60/100\n",
      "125973/125973 [==============================] - 2s 17us/step - loss: 0.4274 - acc: 0.9431 - val_loss: 0.7618 - val_acc: 0.7483\n",
      "Epoch 61/100\n",
      "125973/125973 [==============================] - 2s 17us/step - loss: 0.4265 - acc: 0.9432 - val_loss: 0.7637 - val_acc: 0.7480\n",
      "Epoch 62/100\n",
      "125973/125973 [==============================] - 2s 17us/step - loss: 0.4256 - acc: 0.9433 - val_loss: 0.7642 - val_acc: 0.7481\n",
      "Epoch 63/100\n",
      "125973/125973 [==============================] - 2s 17us/step - loss: 0.4248 - acc: 0.9433 - val_loss: 0.7660 - val_acc: 0.7480\n",
      "Epoch 64/100\n",
      "125973/125973 [==============================] - 2s 17us/step - loss: 0.4240 - acc: 0.9434 - val_loss: 0.7654 - val_acc: 0.7484\n",
      "Epoch 65/100\n",
      "125973/125973 [==============================] - 2s 17us/step - loss: 0.4231 - acc: 0.9435 - val_loss: 0.7663 - val_acc: 0.7484\n",
      "Epoch 66/100\n",
      "125973/125973 [==============================] - 2s 17us/step - loss: 0.4222 - acc: 0.9435 - val_loss: 0.7669 - val_acc: 0.7486\n",
      "Epoch 67/100\n",
      "125973/125973 [==============================] - 2s 17us/step - loss: 0.4214 - acc: 0.9436 - val_loss: 0.7677 - val_acc: 0.7484\n",
      "Epoch 68/100\n",
      "125973/125973 [==============================] - 2s 17us/step - loss: 0.4205 - acc: 0.9436 - val_loss: 0.7684 - val_acc: 0.7483\n",
      "Epoch 69/100\n",
      "125973/125973 [==============================] - 2s 17us/step - loss: 0.4197 - acc: 0.9437 - val_loss: 0.7699 - val_acc: 0.7480\n",
      "Epoch 70/100\n",
      "125973/125973 [==============================] - 2s 17us/step - loss: 0.4188 - acc: 0.9437 - val_loss: 0.7700 - val_acc: 0.7480\n",
      "Epoch 71/100\n",
      "125973/125973 [==============================] - 2s 17us/step - loss: 0.4168 - acc: 0.9438 - val_loss: 0.7686 - val_acc: 0.7482\n",
      "Epoch 72/100\n",
      "125973/125973 [==============================] - 2s 17us/step - loss: 0.4157 - acc: 0.9438 - val_loss: 0.7699 - val_acc: 0.7476\n",
      "Epoch 73/100\n",
      "125973/125973 [==============================] - 2s 17us/step - loss: 0.4148 - acc: 0.9438 - val_loss: 0.7698 - val_acc: 0.7472\n",
      "Epoch 74/100\n",
      "125973/125973 [==============================] - 2s 17us/step - loss: 0.4141 - acc: 0.9439 - val_loss: 0.7700 - val_acc: 0.7461\n",
      "Epoch 75/100\n",
      "125973/125973 [==============================] - 2s 17us/step - loss: 0.4132 - acc: 0.9439 - val_loss: 0.7704 - val_acc: 0.7433\n",
      "Epoch 76/100\n",
      "125973/125973 [==============================] - 2s 17us/step - loss: 0.4123 - acc: 0.9440 - val_loss: 0.7717 - val_acc: 0.7404\n",
      "Epoch 77/100\n",
      "125973/125973 [==============================] - 2s 17us/step - loss: 0.4406 - acc: 0.9438 - val_loss: 0.8039 - val_acc: 0.7370\n",
      "Epoch 78/100\n",
      "125973/125973 [==============================] - 2s 17us/step - loss: 0.4446 - acc: 0.9435 - val_loss: 0.8051 - val_acc: 0.7353\n",
      "Epoch 79/100\n",
      "125973/125973 [==============================] - 2s 17us/step - loss: 0.4414 - acc: 0.9432 - val_loss: 0.8060 - val_acc: 0.7344\n",
      "Epoch 80/100\n",
      "125973/125973 [==============================] - 2s 17us/step - loss: 0.4381 - acc: 0.9430 - val_loss: 0.8066 - val_acc: 0.7335\n",
      "Epoch 81/100\n",
      "125973/125973 [==============================] - 2s 17us/step - loss: 0.4352 - acc: 0.9436 - val_loss: 0.8074 - val_acc: 0.7332\n",
      "Epoch 82/100\n",
      "125973/125973 [==============================] - 2s 17us/step - loss: 0.4329 - acc: 0.9437 - val_loss: 0.8080 - val_acc: 0.7327\n",
      "Epoch 83/100\n",
      "125973/125973 [==============================] - 2s 17us/step - loss: 0.4308 - acc: 0.9437 - val_loss: 0.8081 - val_acc: 0.7326\n",
      "Epoch 84/100\n",
      "125973/125973 [==============================] - 2s 19us/step - loss: 0.4290 - acc: 0.9438 - val_loss: 0.8076 - val_acc: 0.7327\n",
      "Epoch 85/100\n",
      "125973/125973 [==============================] - 2s 17us/step - loss: 0.4272 - acc: 0.9439 - val_loss: 0.8065 - val_acc: 0.7328\n",
      "Epoch 86/100\n",
      "125973/125973 [==============================] - 2s 16us/step - loss: 0.4255 - acc: 0.9440 - val_loss: 0.8064 - val_acc: 0.7329\n",
      "Epoch 87/100\n",
      "125973/125973 [==============================] - 2s 17us/step - loss: 0.4240 - acc: 0.9441 - val_loss: 0.8078 - val_acc: 0.7330\n",
      "Epoch 88/100\n",
      "125973/125973 [==============================] - 2s 17us/step - loss: 0.4224 - acc: 0.9441 - val_loss: 0.8094 - val_acc: 0.7331\n",
      "Epoch 89/100\n",
      "125973/125973 [==============================] - 2s 17us/step - loss: 0.4206 - acc: 0.9441 - val_loss: 0.8132 - val_acc: 0.7331\n",
      "Epoch 90/100\n",
      "125973/125973 [==============================] - 2s 17us/step - loss: 0.4192 - acc: 0.9441 - val_loss: 0.8148 - val_acc: 0.7330\n",
      "Epoch 91/100\n",
      "125973/125973 [==============================] - 2s 16us/step - loss: 0.4178 - acc: 0.9442 - val_loss: 0.8176 - val_acc: 0.7329\n",
      "Epoch 92/100\n",
      "125973/125973 [==============================] - 2s 17us/step - loss: 0.4153 - acc: 0.9442 - val_loss: 0.8142 - val_acc: 0.7329\n",
      "Epoch 93/100\n",
      "125973/125973 [==============================] - 2s 17us/step - loss: 0.4082 - acc: 0.9443 - val_loss: 0.8144 - val_acc: 0.7329\n",
      "Epoch 94/100\n",
      "125973/125973 [==============================] - 2s 17us/step - loss: 0.4065 - acc: 0.9443 - val_loss: 0.8154 - val_acc: 0.7330\n",
      "Epoch 95/100\n",
      "125973/125973 [==============================] - 2s 17us/step - loss: 0.4052 - acc: 0.9444 - val_loss: 0.8159 - val_acc: 0.7333\n",
      "Epoch 96/100\n",
      "125973/125973 [==============================] - 2s 17us/step - loss: 0.4039 - acc: 0.9444 - val_loss: 0.8169 - val_acc: 0.7335\n",
      "Epoch 97/100\n",
      "125973/125973 [==============================] - 2s 17us/step - loss: 0.4027 - acc: 0.9445 - val_loss: 0.8178 - val_acc: 0.7335\n",
      "Epoch 98/100\n",
      "125973/125973 [==============================] - 2s 17us/step - loss: 0.4016 - acc: 0.9445 - val_loss: 0.8191 - val_acc: 0.7335\n",
      "Epoch 99/100\n",
      "125973/125973 [==============================] - 2s 17us/step - loss: 0.4005 - acc: 0.9445 - val_loss: 0.8197 - val_acc: 0.7335\n",
      "Epoch 100/100\n",
      "125973/125973 [==============================] - 2s 17us/step - loss: 0.3994 - acc: 0.9446 - val_loss: 0.8207 - val_acc: 0.7336\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1fc9dff13c8>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras import optimizers\n",
    "opt = optimizers.SGD(lr=0.00001)\n",
    "newmodel.compile(loss='categorical_crossentropy',\n",
    "          optimizer=opt, \n",
    "          metrics=['accuracy']) \n",
    "\n",
    "newmodel.fit(train_X, train_Y,\n",
    "      epochs=100,\n",
    "      batch_size=128,\n",
    "      shuffle=True,\n",
    "      validation_data=(test_X, test_Y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 2s 37ms/step\n",
      "Accuracy:  0.733632028103\n"
     ]
    }
   ],
   "source": [
    "scores = newmodel.evaluate(test_X, test_Y, verbose=1, steps=50) \n",
    "print(\"Accuracy: \", scores[1])\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
